import OpenAI from 'openai';
import { supabase } from '../supabase';

// Configuraci√≥n de OpenAI
const openaiApiKey = import.meta.env.VITE_OPENAI_API_KEY?.trim() || '';

if (!openaiApiKey) {
  console.warn('‚ö†Ô∏è OpenAI API key not found. Please set VITE_OPENAI_API_KEY in your .env file');
}

const openai = openaiApiKey ? new OpenAI({
  apiKey: openaiApiKey,
  dangerouslyAllowBrowser: true, // Solo para MVP - en producci√≥n usar backend
}) : null;

export interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
  sources?: {
    title: string;
    excerpt: string;
  }[];
}

export interface ChatQueryResponse {
  answer: string;
  sources: {
    title: string;
    excerpt: string;
  }[];
}

interface DocumentChunk {
  id: string;
  document_id: string;
  chunk_index: number;
  content: string;
  embedding?: number[];
  similarity?: number; // Similitud calculada para el chunk
}

/**
 * Genera un embedding para el texto usando OpenAI
 */
async function generateEmbedding(text: string): Promise<number[]> {
  if (!openai) {
    throw new Error('OpenAI no est√° configurado. Verifica VITE_OPENAI_API_KEY en tu archivo .env');
  }

  try {
    const response = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: text,
    });

    return response.data[0].embedding;
  } catch (error) {
    console.error('Error generating embedding:', error);
    throw new Error('Error al generar el embedding. Verifica tu API key de OpenAI.');
  }
}

/**
 * Calcula la similitud coseno entre dos vectores
 */
function cosineSimilarity(a: number[], b: number[]): number {
  if (a.length !== b.length) {
    return 0;
  }
  
  const dotProduct = a.reduce((sum, val, i) => sum + val * (b[i] || 0), 0);
  const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
  const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
  
  if (magnitudeA === 0 || magnitudeB === 0) {
    return 0;
  }
  
  return dotProduct / (magnitudeA * magnitudeB);
}

/**
 * Busca chunks similares usando pgvector en Supabase
 * Retorna chunks con su similitud calculada
 */
async function searchSimilarChunks(embedding: number[], limit: number = 5): Promise<DocumentChunk[]> {
  try {
    // Usar la funci√≥n de b√∫squeda por similitud de pgvector
    const { data, error } = await supabase.rpc('match_document_chunks', {
      query_embedding: embedding,
      match_threshold: 0.5, // Threshold m√°s estricto
      match_count: limit,
    });

    if (error) {
      // Si la funci√≥n RPC no existe, intentar b√∫squeda alternativa
      console.warn('RPC function not found, trying alternative search:', error);
      
      // B√∫squeda alternativa: obtener todos los chunks y calcular similitud en el cliente
      // NOTA: Esto no es eficiente para producci√≥n, pero funciona para MVP
      const { data: allChunks, error: fetchError } = await supabase
        .from('document_chunks')
        .select('id, document_id, chunk_index, content, embedding')
        .not('embedding', 'is', null)
        .limit(200); // Aumentar l√≠mite para tener m√°s opciones

      if (fetchError) {
        throw fetchError;
      }

      if (!allChunks || allChunks.length === 0) {
        console.warn('No se encontraron chunks con embeddings en la base de datos');
        console.log('Esto significa que los documentos no han sido procesados a√∫n.');
        return [];
      }

      console.log(`Encontrados ${allChunks.length} chunks con embeddings. Calculando similitud...`);

      // Calcular similitud coseno para todos los chunks
      const chunksWithSimilarity = allChunks
        .map((chunk: any) => {
          // Los embeddings pueden venir como array o como string JSON desde Supabase
          let chunkEmbedding: number[] = [];
          
          if (Array.isArray(chunk.embedding)) {
            chunkEmbedding = chunk.embedding;
          } else if (typeof chunk.embedding === 'string') {
            try {
              chunkEmbedding = JSON.parse(chunk.embedding);
            } catch (e) {
              console.warn('Error parseando embedding como JSON:', e);
              return null;
            }
          } else {
            console.warn('Embedding en formato desconocido:', typeof chunk.embedding);
            return null;
          }

          if (!Array.isArray(chunkEmbedding) || chunkEmbedding.length === 0) {
            return null;
          }
          
          // Verificar que los embeddings tengan la misma dimensi√≥n
          if (chunkEmbedding.length !== embedding.length) {
            console.warn(`Dimension mismatch: query=${embedding.length}, chunk=${chunkEmbedding.length}`);
            return null;
          }
          
          // Calcular similitud coseno
          const similarity = cosineSimilarity(embedding, chunkEmbedding);

          return { ...chunk, similarity };
        })
        .filter((chunk: any) => chunk !== null)
        .sort((a: any, b: any) => b.similarity - a.similarity);

      console.log(`Chunks con similitud calculada: ${chunksWithSimilarity.length}`);
      console.log(`Top similitudes:`, chunksWithSimilarity.map((c: any) => c.similarity.toFixed(3)).slice(0, 10));

      // Retornar chunks con similitud (sin filtrar aqu√≠, se filtrar√° despu√©s por documento)
      return chunksWithSimilarity.slice(0, limit * 2) as DocumentChunk[]; // Obtener m√°s para tener opciones
    }

    // Si la funci√≥n RPC funciona, calcular similitud para los resultados
    if (data && data.length > 0) {
      // Si la funci√≥n RPC ya devuelve similitud, usarla
      // Si no, calcularla
      return data.map((chunk: any) => {
        if (chunk.similarity !== undefined) {
          return chunk as DocumentChunk;
        }
        // Calcular similitud si no viene en la respuesta
        if (chunk.embedding && Array.isArray(chunk.embedding)) {
          const similarity = cosineSimilarity(embedding, chunk.embedding);
          return { ...chunk, similarity } as DocumentChunk;
        }
        return chunk as DocumentChunk;
      });
    }

    return [];
  } catch (error) {
    console.error('Error searching similar chunks:', error);
    return [];
  }
}

/**
 * Obtiene informaci√≥n del documento desde su ID
 */
async function getDocumentInfo(documentId: string): Promise<{ file_name: string; department?: { name: string } } | null> {
  try {
    const { data, error } = await supabase
      .from('documents')
      .select(`
        file_name,
        departments (name)
      `)
      .eq('id', documentId)
      .single();

    if (error) {
      console.error('Error fetching document info:', error);
      return null;
    }

    return data;
  } catch (error) {
    console.error('Error in getDocumentInfo:', error);
    return null;
  }
}

/**
 * Detecta si el mensaje es un saludo (no requiere RAG)
 */
function isGreeting(message: string): boolean {
  const lowerMessage = message.toLowerCase().trim();
  const greetings = [
    'hi',
    'hola',
    'hello',
    'hey',
    'buenos d√≠as',
    'buenos dias',
    'buenas tardes',
    'buenas noches',
    'saludos',
    'qu√© tal',
    'que tal',
    'c√≥mo est√°s',
    'como estas',
    'c√≥mo est√°s?',
    'como estas?',
    'buen d√≠a',
    'buen dia',
    'buena tarde',
    'buena noche',
  ];
  
  // Verificar si el mensaje es solo un saludo (sin m√°s contenido)
  const isOnlyGreeting = greetings.some(greeting => {
    const trimmed = lowerMessage.replace(/[.,!?;:]/g, '').trim();
    return trimmed === greeting || trimmed.startsWith(greeting + ' ');
  });
  
  // Tambi√©n verificar si el mensaje es muy corto y contiene un saludo
  const hasGreeting = greetings.some(greeting => lowerMessage.includes(greeting));
  const isShortMessage = lowerMessage.split(/\s+/).length <= 5;
  
  return isOnlyGreeting || (hasGreeting && isShortMessage);
}

/**
 * Responde a saludos sin usar RAG
 */
function answerGreeting(): ChatQueryResponse {
  const greetings = [
    '¬°Hola! üëã Me da mucho gusto ayudarte. ¬øEn qu√© puedo asistirte hoy?',
    '¬°Hola! üòä Estoy aqu√≠ para ayudarte a encontrar informaci√≥n en tus documentos. ¬øQu√© te gustar√≠a saber?',
    '¬°Hola! Bienvenido. Cu√©ntame, ¬øqu√© informaci√≥n necesitas buscar hoy?',
  ];
  const randomGreeting = greetings[Math.floor(Math.random() * greetings.length)];
  
  return {
    answer: randomGreeting,
    sources: [],
  };
}

/**
 * Detecta si una pregunta es sobre el sistema mismo (no requiere RAG)
 */
function isSystemQuestion(question: string): boolean {
  const lowerQuestion = question.toLowerCase();
  const systemKeywords = [
    'cu√°ntos documentos',
    'cuantos documentos',
    'qu√© documentos',
    'que documentos',
    'qu√© informaci√≥n puedo',
    'que informaci√≥n puedo',
    'c√≥mo funciona el sistema',
    'como funciona el sistema',
    'qu√© tipos de documentos',
    'que tipos de documentos',
    'cu√°ntos archivos',
    'cuantos archivos',
    'cu√°ntos archivos hay',
    'cuantos archivos hay',
    'cu√°ntos documentos hay',
    'cuantos documentos hay',
  ];
  
  return systemKeywords.some(keyword => lowerQuestion.includes(keyword));
}

/**
 * Responde preguntas sobre el sistema sin usar RAG
 */
async function answerSystemQuestion(question: string): Promise<ChatQueryResponse> {
  const lowerQuestion = question.toLowerCase();
  
  // Contar documentos
  if (lowerQuestion.includes('cu√°ntos documentos') || lowerQuestion.includes('cuantos documentos') || 
      lowerQuestion.includes('cu√°ntos archivos') || lowerQuestion.includes('cuantos archivos')) {
    const { count: documentsCount } = await supabase
      .from('documents')
      .select('*', { count: 'exact', head: true })
      .eq('status', 'processed');
    
    const { count: chunksCount } = await supabase
      .from('document_chunks')
      .select('*', { count: 'exact', head: true })
      .not('embedding', 'is', null);
    
    const docCount = documentsCount || 0;
    const chunkCount = chunksCount || 0;
    
    if (docCount === 0) {
      return {
        answer: 'Por ahora no hay documentos procesados en el sistema. ¬øTe gustar√≠a subir algunos documentos para empezar?',
        sources: [],
      };
    }
    
    return {
      answer: `Actualmente tengo ${docCount} documento${docCount > 1 ? 's' : ''} procesado${docCount > 1 ? 's' : ''} en el sistema, con un total de ${chunkCount} fragmento${chunkCount > 1 ? 's' : ''} de informaci√≥n indexados. ¬°Estoy listo para ayudarte a encontrar lo que necesitas! üòä`,
      sources: [],
    };
  }
  
  // Informaci√≥n sobre qu√© se puede consultar
  if (lowerQuestion.includes('qu√© informaci√≥n puedo') || lowerQuestion.includes('que informaci√≥n puedo')) {
    const { data: documents } = await supabase
      .from('documents')
      .select('file_name, departments(name)')
      .eq('status', 'processed')
      .limit(10);
    
    if (!documents || documents.length === 0) {
      return {
        answer: 'Por ahora no tengo documentos disponibles. ¬øTe gustar√≠a subir algunos? Una vez que los subas, podr√© ayudarte a encontrar cualquier informaci√≥n que necesites en ellos.',
        sources: [],
      };
    }
    
    const docList = documents.map(doc => `‚Ä¢ ${doc.file_name}`).join('\n');
    return {
      answer: `¬°Claro! Puedo ayudarte a consultar informaci√≥n sobre estos documentos:\n\n${docList}\n\nSolo hazme una pregunta espec√≠fica sobre el contenido de cualquiera de estos documentos y buscar√© la informaci√≥n relevante para responderte. ¬øQu√© te gustar√≠a saber? üòä`,
      sources: [],
    };
  }
  
  // C√≥mo funciona el sistema
  if (lowerQuestion.includes('c√≥mo funciona') || lowerQuestion.includes('como funciona')) {
    return {
      answer: '¬°Te explico c√≥mo trabajo! üòä\n\nCuando me haces una pregunta:\n\n1. Analizo tu pregunta usando inteligencia artificial para entender qu√© buscas\n2. Busco en todos los documentos los fragmentos m√°s relevantes a tu pregunta\n3. Genero una respuesta clara basada en la informaci√≥n que encontr√©\n4. Te muestro las fuentes de donde obtuve la informaci√≥n para que puedas verificarla\n\nB√°sicamente, soy como un asistente que lee todos tus documentos y te ayuda a encontrar la informaci√≥n que necesitas de forma r√°pida y precisa. ¬øHay algo espec√≠fico que te gustar√≠a buscar?',
      sources: [],
    };
  }
  
  // Tipos de documentos
  if (lowerQuestion.includes('qu√© tipos de documentos') || lowerQuestion.includes('que tipos de documentos')) {
    return {
      answer: 'Acepto los siguientes tipos de documentos:\n\n‚Ä¢ Archivos PDF (.pdf)\n‚Ä¢ Archivos de texto (.txt)\n‚Ä¢ Archivos Markdown (.md)\n\nUna vez que los subas, los proceso autom√°ticamente para extraer su contenido y hacerlo buscable. ¬°Es muy f√°cil! Solo s√∫belos y podr√°s hacer preguntas sobre ellos de inmediato.',
      sources: [],
    };
  }
  
  // Respuesta gen√©rica para preguntas del sistema
  return {
    answer: '¬°Claro! Estoy aqu√≠ para ayudarte. Puedes hacerme preguntas sobre los documentos que tengas subidos, o si necesitas ayuda con algo m√°s espec√≠fico del sistema, con gusto te ayudo. ¬øQu√© te gustar√≠a saber?',
    sources: [],
  };
}

/**
 * Detecta si la respuesta indica que no se encontr√≥ informaci√≥n relevante
 */
function indicatesNoInformation(answer: string): boolean {
  const lowerAnswer = answer.toLowerCase();
  const noInfoPhrases = [
    'no tengo informaci√≥n',
    'no encontr√© informaci√≥n',
    'no tengo esa informaci√≥n',
    'no est√° en el contexto',
    'no est√° disponible',
    'no puedo responder',
    'no hay informaci√≥n',
    'no se encontr√≥',
    'no se encuentra',
  ];
  
  return noInfoPhrases.some(phrase => lowerAnswer.includes(phrase));
}

/**
 * Env√≠a una consulta usando RAG (Retrieval-Augmented Generation)
 * 
 * @param question - La pregunta del usuario
 * @param conversationHistory - Historial de conversaci√≥n (opcional, para contexto)
 * @returns Respuesta de la IA con fuentes
 */
export async function queryChat(
  question: string,
  conversationHistory: ChatMessage[] = []
): Promise<ChatQueryResponse> {
  try {
    if (!openai) {
      throw new Error('OpenAI no est√° configurado. Por favor, configura VITE_OPENAI_API_KEY en tu archivo .env');
    }

    // 0. Verificar si es un saludo (no requiere RAG)
    if (isGreeting(question)) {
      return answerGreeting();
    }

    // 0.1. Verificar si es una pregunta sobre el sistema (no requiere RAG)
    if (isSystemQuestion(question)) {
      return await answerSystemQuestion(question);
    }

    // 1. Verificar que hay documentos en el sistema
    const { count: documentsCount } = await supabase
      .from('documents')
      .select('*', { count: 'exact', head: true })
      .eq('status', 'processed');

    if (!documentsCount || documentsCount === 0) {
      return {
        answer: 'Por ahora no tengo documentos disponibles para consultar. ¬øTe gustar√≠a subir algunos documentos primero? Una vez que los subas, podr√© ayudarte a encontrar la informaci√≥n que necesitas.',
        sources: [],
      };
    }

    // 2. Verificar que hay chunks procesados (con embeddings)
    const { count: chunksCount } = await supabase
      .from('document_chunks')
      .select('*', { count: 'exact', head: true })
      .not('embedding', 'is', null);

    if (!chunksCount || chunksCount === 0) {
      return {
        answer: `Veo que hay ${documentsCount} documento${documentsCount > 1 ? 's' : ''} en el sistema, pero a√∫n se est√°n procesando. üòä\n\nLos documentos se procesan autom√°ticamente cuando los subes. Si acabas de subirlos, dale unos momentos para que terminen de procesarse. Una vez que est√©n listos, podr√© ayudarte a encontrar cualquier informaci√≥n que necesites.\n\n**Para verificar:**\n‚Ä¢ Revisa en la p√°gina de "Subir Documentos" que los documentos hayan terminado de procesarse\n‚Ä¢ Aseg√∫rate de que sean archivos TXT, PDF o MD\n‚Ä¢ Si pasan varios minutos y a√∫n no se procesan, verifica que la configuraci√≥n est√© correcta\n\n¬°Vuelve en un momento y estar√© listo para ayudarte!`,
        sources: [],
      };
    }

    // 2. Generar embedding de la pregunta
    const questionEmbedding = await generateEmbedding(question);

    // 3. Buscar chunks similares (obtener m√°s para tener opciones)
    const similarChunks = await searchSimilarChunks(questionEmbedding, 10);

    if (similarChunks.length === 0) {
      return {
        answer: 'Hmm, no encontr√© informaci√≥n espec√≠fica sobre eso en los documentos que tengo disponibles. ¬øPodr√≠as reformular tu pregunta o darme m√°s detalles sobre lo que buscas? Estoy aqu√≠ para ayudarte a encontrar lo que necesitas.',
        sources: [],
      };
    }

    // 4. Filtrar y agrupar chunks por documento seg√∫n similitud
    // Umbral de similitud m√≠nimo para considerar un chunk relevante
    const MIN_SIMILARITY_THRESHOLD = 0.5;
    
    // Agrupar chunks por documento y encontrar la similitud m√°xima por documento
    const chunksByDocument = new Map<string, { chunks: DocumentChunk[], maxSimilarity: number }>();
    
    for (const chunk of similarChunks) {
      const similarity = chunk.similarity || 0;
      
      // Solo considerar chunks con similitud suficiente
      if (similarity < MIN_SIMILARITY_THRESHOLD) {
        continue;
      }
      
      const docId = chunk.document_id;
      const existing = chunksByDocument.get(docId);
      
      if (!existing) {
        chunksByDocument.set(docId, { chunks: [chunk], maxSimilarity: similarity });
      } else {
        existing.chunks.push(chunk);
        if (similarity > existing.maxSimilarity) {
          existing.maxSimilarity = similarity;
        }
      }
    }

    // Ordenar documentos por similitud m√°xima (de mayor a menor)
    const sortedDocuments = Array.from(chunksByDocument.entries())
      .sort((a, b) => b[1].maxSimilarity - a[1].maxSimilarity);

    if (sortedDocuments.length === 0) {
      return {
        answer: 'No encontr√© informaci√≥n que coincida directamente con tu pregunta en los documentos disponibles. ¬øPodr√≠as ser un poco m√°s espec√≠fico sobre lo que necesitas? Por ejemplo, puedes mencionar el tema o el √°rea de inter√©s, y con gusto te ayudo a buscar la informaci√≥n relevante.',
        sources: [],
      };
    }

    // 5. Seleccionar documentos para incluir en la respuesta
    // Si hay m√∫ltiples documentos con alta similitud (>= 0.6), incluir hasta 2
    // Si solo hay un documento con alta similitud, solo incluir ese
    // Si hay documentos con similitud media (0.5-0.6), incluir solo el mejor
    const HIGH_SIMILARITY_THRESHOLD = 0.6;
    
    const highSimilarityDocs = sortedDocuments.filter(([_, data]) => data.maxSimilarity >= HIGH_SIMILARITY_THRESHOLD);
    const selectedDocuments = highSimilarityDocs.length > 1 
      ? highSimilarityDocs.slice(0, 2) // Si hay m√∫ltiples con alta similitud, incluir hasta 2
      : sortedDocuments.slice(0, 1); // Si solo hay uno o todos tienen similitud media, solo el mejor

    // 6. Construir el contexto con los chunks de los documentos seleccionados
    const contextChunks: DocumentChunk[] = [];
    for (const [docId, data] of selectedDocuments) {
      // Tomar el chunk con mayor similitud de cada documento seleccionado
      const bestChunk = data.chunks.sort((a, b) => (b.similarity || 0) - (a.similarity || 0))[0];
      if (bestChunk) {
        contextChunks.push(bestChunk);
      }
    }

    const context = contextChunks
      .map((chunk, index) => `[Documento ${index + 1}]\n${chunk.content}`)
      .join('\n\n---\n\n');

    // 7. Obtener informaci√≥n de los documentos fuente seleccionados
    const selectedDocumentIds = selectedDocuments.map(([docId]) => docId);
    const documentInfos = await Promise.all(
      selectedDocumentIds.map(id => getDocumentInfo(id))
    );

    const sources = documentInfos
      .filter((info): info is NonNullable<typeof info> => info !== null)
      .map((info, index) => {
        const docId = selectedDocumentIds[index];
        const docData = chunksByDocument.get(docId);
        const bestChunk = docData?.chunks.sort((a, b) => (b.similarity || 0) - (a.similarity || 0))[0];
        return {
          title: info.file_name,
          excerpt: bestChunk?.content.substring(0, 150) || '',
        };
      });

    // 7. Construir el prompt con el contexto
    const systemPrompt = `Eres un asistente de IA amigable y conversacional que ayuda a los usuarios a encontrar informaci√≥n en sus documentos. Tu personalidad es c√°lida, emp√°tica y natural, como si fueras un compa√±ero de trabajo que est√° ah√≠ para ayudar.

ESTILO DE COMUNICACI√ìN:
- S√© natural y conversacional, como si estuvieras hablando con un amigo o colega
- Usa un tono amigable y accesible, evitando lenguaje rob√≥tico o demasiado formal
- Muestra entusiasmo genuino por ayudar
- S√© emp√°tico cuando no encuentres informaci√≥n espec√≠fica
- Usa variaci√≥n en tus respuestas para evitar sonar repetitivo
- Puedes usar emojis ocasionalmente para hacer la conversaci√≥n m√°s amena (pero con moderaci√≥n)

INSTRUCCIONES:
- Si el usuario pregunta sobre algo que NO est√° en el contexto proporcionado:
  * NO digas "no tengo informaci√≥n" o "no encontr√© informaci√≥n" de forma directa y fr√≠a
  * En su lugar, s√© emp√°tico y ofrece ayuda: "No encontr√© informaci√≥n espec√≠fica sobre eso en los documentos que tengo, pero puedo ayudarte. ¬øPodr√≠as darme m√°s detalles sobre lo que buscas? Por ejemplo, ¬øes sobre [tema relacionado] o algo diferente?"
  * Sugiere formas alternativas de buscar o reformular la pregunta de manera amigable
  * Mant√©n un tono positivo y √∫til, como si realmente quisieras ayudar

- Si la informaci√≥n S√ç est√° en el contexto:
  * Responde de forma clara y completa usando la informaci√≥n proporcionada
  * S√© natural en tu explicaci√≥n, como si estuvieras explic√°ndoselo a un compa√±ero
  * Si es apropiado, puedes hacer conexiones o dar contexto adicional de forma conversacional
  * Cita los documentos fuente cuando sea relevante, pero hazlo de forma natural

- Si el usuario pregunta m√°s detalles sobre un tema:
  * Ampl√≠a la informaci√≥n de forma natural, conectando con lo que ya se ha discutido
  * Mant√©n el contexto de la conversaci√≥n

- Si la pregunta es vaga o no espec√≠fica:
  * Responde de forma amigable pidiendo aclaraci√≥n: "Me gustar√≠a ayudarte mejor. ¬øPodr√≠as contarme un poco m√°s sobre [tema]? Por ejemplo, ¬øqu√© aspecto espec√≠fico te interesa?"

- Responde SOLO usando la informaci√≥n proporcionada en el contexto cuando sea relevante
- Responde en el mismo idioma que la pregunta del usuario
- S√© preciso pero tambi√©n conversacional - no necesitas ser extremadamente conciso si puedes hacer la respuesta m√°s natural

CONTEXTO DE DOCUMENTOS:
${context}`;

    // Solo incluir historial si la pregunta actual requiere contexto de documentos
    // No incluir historial si la pregunta anterior era sobre el sistema
    const recentUserMessages = conversationHistory
      .filter(msg => msg.role === 'user')
      .slice(-2); // √öltimas 2 preguntas para contexto
    
    // Filtrar mensajes del sistema del historial para evitar confusi√≥n
    const relevantHistory = recentUserMessages
      .filter(msg => !isSystemQuestion(msg.content))
      .map(msg => ({ role: 'user' as const, content: msg.content }));
    
    const userMessages = relevantHistory;

    // 8. Llamar a OpenAI Chat Completion API
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        ...userMessages,
        { role: 'user', content: question },
      ],
      temperature: 0.8, // Aumentado para respuestas m√°s naturales y variadas
      max_tokens: 600, // Aumentado para respuestas m√°s completas y naturales
    });

    const answer = completion.choices[0]?.message?.content || 'No pude generar una respuesta.';

    // Si la respuesta indica que no hay informaci√≥n, no mostrar fuentes
    const shouldShowSources = !indicatesNoInformation(answer) && sources.length > 0;

    return {
      answer,
      sources: shouldShowSources ? sources : [],
    };
  } catch (error) {
    console.error('Error in queryChat:', error);
    
    if (error instanceof Error) {
      throw error;
    }
    
    throw new Error('Error al procesar la consulta. Por favor, verifica tu configuraci√≥n de OpenAI.');
  }
}
